# -*- coding: utf-8 -*-
"""XGBoost(PhonologicalAwarenessRelatedFeatures).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1o5hnky7FiNQ-fkBR-A2CVgdAvjdBcFAb

**Importing Data**
"""

import io
import pandas as pd
from google.colab import files

uploaded = files.upload()

df = pd.read_excel(io.BytesIO(uploaded.get('data analysis.xlsx')))

import numpy as np
pd.pandas.set_option('Display.max_columns',None)
pd.pandas.set_option('Display.max_rows',None)

"""**Data cleaning**"""

df.isnull().sum()

df.duplicated().sum()

# There is no null and duplicate value in the dataset.

"""**Data Preparation**"""

df = df.drop('Gender',axis=1)

df = df.drop('Age',axis=1)

import matplotlib.pyplot as plt
from sklearn.impute import SimpleImputer
from sklearn import preprocessing
from sklearn.preprocessing import LabelEncoder,OneHotEncoder,StandardScaler
from sklearn.metrics import accuracy_score, confusion_matrix,roc_auc_score
from sklearn import metrics
from sklearn.model_selection import RandomizedSearchCV, GridSearchCV
import xgboost as xgb

label_encoder = preprocessing.LabelEncoder()
df['Nativelang']= label_encoder.fit_transform(df['Nativelang'])
df['Otherlang']= label_encoder.fit_transform(df['Otherlang'])
df['Dyslexia']= label_encoder.fit_transform(df['Dyslexia'])

df

"""**Feature Selection**"""

df1 = pd.DataFrame({})

for i in range(1,33):
  if(i<9 or 26<=i<30 or i==31 or i==32):
    df1 = df1.append(df["Clicks"+ str(i)])
    df1 = df1.append(df["Hits"+str(i)])
    df1 = df1.append(df["Misses"+str(i)])
    df1 = df1.append(df["Score"+str(i)])
    df1 = df1.append(df["Accuracy"+str(i)])
    df1 = df1.append(df["Missrate"+str(i)])

df1 = df1.append(df["Dyslexia"])

df2 = df1.T

df2

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(df2.drop(labels=['Dyslexia'],axis=1),df2['Dyslexia'],
                                                                                        test_size=0.2,random_state=0)

"""**Model**"""

classifier = xgb.XGBClassifier()
classifier.fit(x_train, y_train)

pred = classifier.predict(x_test)
y_train_predict = classifier.predict(x_train)

print("Training Accuracy", accuracy_score(y_train, y_train_predict))
Accuracy = metrics.accuracy_score(y_test, pred)
print("Testing Accuracy",Accuracy)

from sklearn.metrics import classification_report
print(classification_report(y_test, pred))
pd.crosstab(y_test, pred)

"""**Parameter Tuning**"""

classifier = xgb.XGBClassifier(
 max_depth = 6,
 subsample = 0.7,
# colsample_bylevel = 0.2,
# colsample_bytree = 0.1,
 n_estimators = 100,
 learning_rate = 0.08,
 min_child_weight = 1,
 reg_lambda = 10,
 scale_pos_weight = 18

)
classifier.fit(x_train, y_train)

pred = classifier.predict(x_test)
y_train_predict = classifier.predict(x_train)

print("Training Accuracy", accuracy_score(y_train, y_train_predict))
Accuracy = metrics.accuracy_score(y_test, pred)
print("Testing Accuracy",Accuracy)

"""**Model Evaluation**"""

from sklearn.metrics import classification_report
print(classification_report(y_test, pred))
pd.crosstab(y_test, pred)

confusion_matrix = metrics.confusion_matrix(y_test, pred)

cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])

cm_display.plot()
plt.show()

Precision = metrics.precision_score(y_test, pred)
print(Precision)

Sensitivity_recall = metrics.recall_score(y_test, pred)
print(Sensitivity_recall)

Specificity = metrics.recall_score(y_test, pred, pos_label=0)
print(Specificity)

F1_score = metrics.f1_score(y_test, pred)
print(F1_score)

from sklearn.metrics import roc_auc_score
from sklearn.metrics import roc_curve
ns_probs = [0 for _ in range(len(y_test))]
XB_probs = classifier.predict_proba(x_test)
# keep probabilities for the positive outcome only
XB_probs = XB_probs[:, 1]
# calculate scores
ns_auc = roc_auc_score(y_test, ns_probs)
XB_auc = roc_auc_score(y_test, XB_probs)
# summarize scores
print('No Skill: ROC AUC=%.3f' % (ns_auc))
print('XGBoost: ROC AUC=%.3f' % (XB_auc))
# calculate roc curves
ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)
XB_fpr, XB_tpr, _ = roc_curve(y_test, XB_probs)
# plot the roc curve for the model
plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')
plt.plot(XB_fpr, XB_tpr, marker='.', label='XGBoost')
# axis labels
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
# show the legend
plt.legend()
# show the plot
plt.show()