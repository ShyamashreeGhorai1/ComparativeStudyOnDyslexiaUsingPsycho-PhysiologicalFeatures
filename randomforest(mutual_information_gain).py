# -*- coding: utf-8 -*-
"""RandomForest(Mutual_Information_Gain).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ajoIh52BUyriIjCjKkxAoCFe9dNcEits

**Importing Data**
"""

import io
import pandas as pd
from google.colab import files

uploaded = files.upload()

df = pd.read_excel(io.BytesIO(uploaded.get('data analysis.xlsx')))

import numpy as np
pd.pandas.set_option('Display.max_columns',None)
pd.pandas.set_option('Display.max_rows',None)

"""***Data Cleaning***"""

df.isnull().sum()

df.duplicated().sum()

# There is no missing and duplicate value in the dataset.

"""**Data Preparation**"""

df = df.drop('Gender',axis=1)

df = df.drop('Age',axis=1)

import matplotlib.pyplot as plt
from sklearn.impute import SimpleImputer
from sklearn import preprocessing
from sklearn.preprocessing import LabelEncoder,OneHotEncoder,StandardScaler
from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, f1_score, recall_score,roc_auc_score
from sklearn import metrics
from sklearn.model_selection import RandomizedSearchCV, GridSearchCV

label_encoder = preprocessing.LabelEncoder()
df['Nativelang']= label_encoder.fit_transform(df['Nativelang'])
df['Otherlang']= label_encoder.fit_transform(df['Otherlang'])
df['Dyslexia']= label_encoder.fit_transform(df['Dyslexia'])

df

df.shape

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(df.drop(labels=['Dyslexia'],axis=1),df['Dyslexia'],
                                                                                        test_size=0.2,random_state=0)

"""**Feature selection**"""

from sklearn.feature_selection import mutual_info_classif
# determine the mutual information
mutual_info = mutual_info_classif(x_train, y_train)
mutual_info

mutual_info = pd.Series(mutual_info)
mutual_info.index = x_train.columns
mutual_info.sort_values(ascending=False)

#let's plot the ordered mutual_info values per feature
mutual_info.sort_values(ascending=False).plot.bar(figsize=(15, 5))

from sklearn.feature_selection import SelectKBest

# Now we Will select the  top 100 important features
sel_cols = SelectKBest(mutual_info_classif, k=100)
sel_cols.fit(x_train, y_train)
x_train.columns[sel_cols.get_support()]

from sklearn.ensemble import RandomForestClassifier

classifier = RandomForestClassifier()
classifier.fit(x_train, y_train)

pred = classifier.predict(x_test)
y_train_predict = classifier.predict(x_train)

print("Training Accuracy", accuracy_score(y_train, y_train_predict))
Accuracy = metrics.accuracy_score(y_test, pred)
print("Testing Accuracy", Accuracy)

from sklearn.metrics import classification_report
print(classification_report(y_test, pred))
pd.crosstab(y_test, pred)

"""**Parameter Tuning**"""

classifier = RandomForestClassifier(
    min_samples_split = 20,
    class_weight = "balanced",
    n_estimators = 2000,
    min_samples_leaf = 40,
    n_jobs = -1
)

classifier.fit(x_train, y_train)

pred = classifier.predict(x_test)
y_train_predict = classifier.predict(x_train)

print("Training Accuracy", accuracy_score(y_train, y_train_predict))
Accuracy = metrics.accuracy_score(y_test, pred)
print("Testing Accuracy", Accuracy)

"""**Model Evaluation**"""

from sklearn.metrics import classification_report
print(classification_report(y_test, pred))
pd.crosstab(y_test, pred)

confusion_matrix = metrics.confusion_matrix(y_test, pred)

cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])

cm_display.plot()
plt.show()

Precision = metrics.precision_score(y_test, pred)
print(Precision)

Sensitivity_recall = metrics.recall_score(y_test, pred)
print(Sensitivity_recall)

Specificity = metrics.recall_score(y_test, pred, pos_label=0)
print(Specificity)

F1_score = metrics.f1_score(y_test, pred)
print(F1_score)

from sklearn.metrics import roc_auc_score
from sklearn.metrics import roc_curve
ns_probs = [0 for _ in range(len(y_test))]
RF_probs = classifier.predict_proba(x_test)
# keep probabilities for the positive outcome only
RF_probs = RF_probs[:, 1]
# calculate scores
ns_auc = roc_auc_score(y_test, ns_probs)
RF_auc = roc_auc_score(y_test, RF_probs)
# summarize scores
print('No Skill: ROC AUC=%.3f' % (ns_auc))
print('Random Forest: ROC AUC=%.3f' % (RF_auc))
# calculate roc curves
ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)
RF_fpr, RF_tpr, _ = roc_curve(y_test, RF_probs)
# plot the roc curve for the model
plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')
plt.plot(RF_fpr, RF_tpr, marker='.', label='Random Forest')
# axis labels
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
# show the legend
plt.legend()
# show the plot
plt.show()



